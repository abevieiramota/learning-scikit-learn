{
 "metadata": {
  "name": "",
  "signature": "sha256:467a0cb1081c1746f970f0d2f49ebcebc793c4b4baf9aba0c5c4f349bb41ba78"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- http://scikit-learn.org/stable/modules/cross_validation.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn import cross_validation\n",
      "from sklearn import svm\n",
      "from itertools import product\n",
      "import pandas as pd\n",
      "from matplotlib import pyplot as pl\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Introdu\u00e7\u00e3o"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()\n",
      "iris.data.shape, iris.target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "((150, 4), (150,))"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, \n",
      "                                                                     iris.target, \n",
      "                                                                     test_size=.4)\n",
      "X_train.shape, y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "((90, 4), (90,))"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
      "clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.96666666666666667"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
      "Cs = [0.0001, 0.01, 1., 10., 100., 1000.]\n",
      "\n",
      "\n",
      "dados = []\n",
      "for kernel, c in product(kernels, Cs):\n",
      "    score = svm.SVC(kernel=kernel, C=c).fit(X_train, y_train).score(X_test, y_test)\n",
      "    dados.append((kernel, c, score))\n",
      "    \n",
      "stats = pd.DataFrame(dados, columns=['kernel', 'C', 'score'])\n",
      "\n",
      "fig = pl.figure()\n",
      "ax = fig.add_subplot(1, 1, 1)\n",
      "\n",
      "for kernel in kernels:\n",
      "    \n",
      "    stats_kernel = stats[stats.kernel==kernel]\n",
      "    \n",
      "    C = stats_kernel.C\n",
      "    scores = stats_kernel.score\n",
      "    \n",
      "    ax.plot(range(len(scores)), scores, label=kernel)\n",
      "    \n",
      "ax.legend(loc='center right')\n",
      "ax.set_xticks(range(len(scores)))\n",
      "ax.set_xticklabels(C.tolist())\n",
      "ax.set_ylim(0., 1.2)\n",
      "ax.set_xlabel('C')\n",
      "ax.set_ylabel('score')\n",
      "ax.grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEPCAYAAAC6Kkg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3a580d8f50>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 5-fold\n",
      "clf = svm.SVC(kernel='linear', C=1.)\n",
      "scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5)\n",
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "array([ 1.        ,  0.96666667,  0.9       ,  0.96666667,  1.        ])"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.97 (+/- 0.07)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross-validation iterators"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "KFold"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- KFold divides all the samples in math:k groups of samples, called folds (if k = n, this is equivalent to the Leave One Out strategy), of equal sizes (if possible). The prediction function is learned using k - 1 folds, and the fold left out is used for test."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
      "Y = np.array([0, 1, 2, 3])\n",
      "\n",
      "# sem \u00edndices, boolean indexing\n",
      "kf = KFold(len(Y), n_folds=2, indices=False)\n",
      "\n",
      "for train, test in kf:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print '%s %s' % (X[train].T, Y[train])\n",
      "    print '%s %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[False False  True  True] [ True  True False False]\n",
        "[[-1.  2.]\n",
        " [-1.  2.]] [2 3]\n",
        "[[ 0.  1.]\n",
        " [ 0.  1.]] [0 1]\n",
        "\n",
        "\n",
        "[ True  True False False] [False False  True  True]\n",
        "[[ 0.  1.]\n",
        " [ 0.  1.]] [0 1]\n",
        "[[-1.  2.]\n",
        " [-1.  2.]] [2 3]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# \u00edndices utilizados com matrizes esparsas\n",
      "kf = KFold(len(Y), n_folds=2, indices=True)\n",
      "\n",
      "for train, test in kf:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print '%s %s' % (X[train].T, Y[train])\n",
      "    print '%s %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2 3] [0 1]\n",
        "[[-1.  2.]\n",
        " [-1.  2.]] [2 3]\n",
        "[[ 0.  1.]\n",
        " [ 0.  1.]] [0 1]\n",
        "\n",
        "\n",
        "[0 1] [2 3]\n",
        "[[ 0.  1.]\n",
        " [ 0.  1.]] [0 1]\n",
        "[[-1.  2.]\n",
        " [-1.  2.]] [2 3]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "StratifiedKFold"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- StratifiedKFold is a variation of k-fold which returns stratified folds: each set contains the same percentage of samples of each target class as the complete set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import StratifiedKFold\n",
      "X = np.array([[0], [1], [2], [3], [4], [5], [6]])\n",
      "Y = np.array([0, 0, 1, 1, 2, 2])\n",
      "\n",
      "skf = StratifiedKFold(Y, n_folds=2)\n",
      "\n",
      "for train, test in skf:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print '%s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print '%s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 3 5] [0 2 4]\n",
        "[[1 3 5]] >>>>> [0 1 2]\n",
        "[[0 2 4]] >>>>> [0 1 2]\n",
        "\n",
        "\n",
        "[0 2 4] [1 3 5]\n",
        "[[0 2 4]] >>>>> [0 1 2]\n",
        "[[1 3 5]] >>>>> [0 1 2]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Leave-One-Out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- LeaveOneOut (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for n samples, we have n different learning sets and n different tests set. This cross-validation procedure does not waste much data as only one sample is removed from the learning set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeaveOneOut\n",
      "\n",
      "loo = LeaveOneOut(len(Y))\n",
      "\n",
      "for train, test in loo:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 2 3 4 5] [0]\n",
        "treino [[1 2 3 4 5]] >>>>> [0 1 1 2 2]\n",
        "teste [[0]] >>>>> [0]\n",
        "\n",
        "\n",
        "[0 2 3 4 5] [1]\n",
        "treino [[0 2 3 4 5]] >>>>> [0 1 1 2 2]\n",
        "teste [[1]] >>>>> [0]\n",
        "\n",
        "\n",
        "[0 1 3 4 5] [2]\n",
        "treino [[0 1 3 4 5]] >>>>> [0 0 1 2 2]\n",
        "teste [[2]] >>>>> [1]\n",
        "\n",
        "\n",
        "[0 1 2 4 5] [3]\n",
        "treino [[0 1 2 4 5]] >>>>> [0 0 1 2 2]\n",
        "teste [[3]] >>>>> [1]\n",
        "\n",
        "\n",
        "[0 1 2 3 5] [4]\n",
        "treino [[0 1 2 3 5]] >>>>> [0 0 1 1 2]\n",
        "teste [[4]] >>>>> [2]\n",
        "\n",
        "\n",
        "[0 1 2 3 4] [5]\n",
        "treino [[0 1 2 3 4]] >>>>> [0 0 1 1 2]\n",
        "teste [[5]] >>>>> [2]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Leave-P-Out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- LeavePOut is very similar to LeaveOneOut as it creates all the possible training/test sets by removing p samples from the complete set. For n samples, this produces ${n \\choose p}$ train-test pairs. Unlike LeaveOneOut and KFold, the test sets will overlap for p > 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeavePOut\n",
      "\n",
      "lpo = LeavePOut(len(Y), 2)\n",
      "\n",
      "for train, test in lpo:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2 3 4 5] [0 1]\n",
        "treino [[2 3 4 5]] >>>>> [1 1 2 2]\n",
        "teste [[0 1]] >>>>> [0 0]\n",
        "\n",
        "\n",
        "[1 3 4 5] [0 2]\n",
        "treino [[1 3 4 5]] >>>>> [0 1 2 2]\n",
        "teste [[0 2]] >>>>> [0 1]\n",
        "\n",
        "\n",
        "[1 2 4 5] [0 3]\n",
        "treino [[1 2 4 5]] >>>>> [0 1 2 2]\n",
        "teste [[0 3]] >>>>> [0 1]\n",
        "\n",
        "\n",
        "[1 2 3 5] [0 4]\n",
        "treino [[1 2 3 5]] >>>>> [0 1 1 2]\n",
        "teste [[0 4]] >>>>> [0 2]\n",
        "\n",
        "\n",
        "[1 2 3 4] [0 5]\n",
        "treino [[1 2 3 4]] >>>>> [0 1 1 2]\n",
        "teste [[0 5]] >>>>> [0 2]\n",
        "\n",
        "\n",
        "[0 3 4 5] [1 2]\n",
        "treino [[0 3 4 5]] >>>>> [0 1 2 2]\n",
        "teste [[1 2]] >>>>> [0 1]\n",
        "\n",
        "\n",
        "[0 2 4 5] [1 3]\n",
        "treino [[0 2 4 5]] >>>>> [0 1 2 2]\n",
        "teste [[1 3]] >>>>> [0 1]\n",
        "\n",
        "\n",
        "[0 2 3 5] [1 4]\n",
        "treino [[0 2 3 5]] >>>>> [0 1 1 2]\n",
        "teste [[1 4]] >>>>> [0 2]\n",
        "\n",
        "\n",
        "[0 2 3 4] [1 5]\n",
        "treino [[0 2 3 4]] >>>>> [0 1 1 2]\n",
        "teste [[1 5]] >>>>> [0 2]\n",
        "\n",
        "\n",
        "[0 1 4 5] [2 3]\n",
        "treino [[0 1 4 5]] >>>>> [0 0 2 2]\n",
        "teste [[2 3]] >>>>> [1 1]\n",
        "\n",
        "\n",
        "[0 1 3 5] [2 4]\n",
        "treino [[0 1 3 5]] >>>>> [0 0 1 2]\n",
        "teste [[2 4]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[0 1 3 4] [2 5]\n",
        "treino [[0 1 3 4]] >>>>> [0 0 1 2]\n",
        "teste [[2 5]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[0 1 2 5] [3 4]\n",
        "treino [[0 1 2 5]] >>>>> [0 0 1 2]\n",
        "teste [[3 4]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[0 1 2 4] [3 5]\n",
        "treino [[0 1 2 4]] >>>>> [0 0 1 2]\n",
        "teste [[3 5]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[0 1 2 3] [4 5]\n",
        "treino [[0 1 2 3]] >>>>> [0 0 1 1]\n",
        "teste [[4 5]] >>>>> [2 2]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Leave-One-Label-Out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- LeaveOneLabelOut (LOLO) is a cross-validation scheme which holds out the samples according to a third-party provided label. This label information can be used to encode arbitrary domain specific stratifications of the samples as integers.\n",
      "Each training set is thus constituted by all the samples except the ones related to a specific label.\n",
      "For example, in the cases of multiple experiments, LOLO can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except oneLeaveOneLabelOut (LOLO) is a cross-validation scheme which holds out the samples according to a third-party provided label. This label information can be used to encode arbitrary domain specific stratifications of the samples as integers.\n",
      "Each training set is thus constituted by all the samples except the ones related to a specific label.\n",
      "For example, in the cases of multiple experiments, LOLO can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one\n",
      "- Another common application is to use time information: for instance the labels could be the year of collection of the samples and thus allow for cross-validation against time-based splits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeaveOneLabelOut\n",
      "\n",
      "# uso trivial, para escolher uma classe para ficar de fora\n",
      "labels = [1, 1, 2, 2, 3, 3]\n",
      "\n",
      "lolo = LeaveOneLabelOut(labels)\n",
      "\n",
      "for train, test in lolo:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2 3 4 5] [0 1]\n",
        "treino [[2 3 4 5]] >>>>> [1 1 2 2]\n",
        "teste [[0 1]] >>>>> [0 0]\n",
        "\n",
        "\n",
        "[0 1 4 5] [2 3]\n",
        "treino [[0 1 4 5]] >>>>> [0 0 2 2]\n",
        "teste [[2 3]] >>>>> [1 1]\n",
        "\n",
        "\n",
        "[0 1 2 3] [4 5]\n",
        "treino [[0 1 2 3]] >>>>> [0 0 1 1]\n",
        "teste [[4 5]] >>>>> [2 2]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Leave-P-Label-Out"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- LeavePLabelOut is similar as Leave-One-Label-Out, but removes samples related to P labels for each training/test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import LeavePLabelOut\n",
      "\n",
      "labels = [1,1,2,2,3,3]\n",
      "\n",
      "lplo = LeavePLabelOut(labels, 2)\n",
      "\n",
      "for train, test in lplo:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[4 5] [0 1 2 3]\n",
        "treino [[4 5]] >>>>> [2 2]\n",
        "teste [[0 1 2 3]] >>>>> [0 0 1 1]\n",
        "\n",
        "\n",
        "[2 3] [0 1 4 5]\n",
        "treino [[2 3]] >>>>> [1 1]\n",
        "teste [[0 1 4 5]] >>>>> [0 0 2 2]\n",
        "\n",
        "\n",
        "[0 1] [2 3 4 5]\n",
        "treino [[0 1]] >>>>> [0 0]\n",
        "teste [[2 3 4 5]] >>>>> [1 1 2 2]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "ShuffleSplit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- The ShuffleSplit iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.\n",
      "It is possible to control the randomness for reproducibility of the results by explicitly seeding the random_state pseudo random number generator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import ShuffleSplit\n",
      "\n",
      "ss = ShuffleSplit(len(Y), n_iter=3, test_size=.25)\n",
      "\n",
      "for train, test in ss:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0 2 1 5] [3 4]\n",
        "treino [[0 2 1 5]] >>>>> [0 1 0 2]\n",
        "teste [[3 4]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[5 0 1 2] [3 4]\n",
        "treino [[5 0 1 2]] >>>>> [2 0 0 1]\n",
        "teste [[3 4]] >>>>> [1 2]\n",
        "\n",
        "\n",
        "[4 3 5 2] [0 1]\n",
        "treino [[4 3 5 2]] >>>>> [2 1 2 1]\n",
        "teste [[0 1]] >>>>> [0 0]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "StratifiedShuffleSplit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- StratifiedShuffleSplit is a variation of ShuffleSplit, which returns stratified splits, i.e which creates splits by preserving the same percentage for each target class as in the complete set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "\n",
      "X = np.arange(0, 11, 1)\n",
      "Y = np.array([0,0,0,1,1,1,2,2,2,3,3])\n",
      "\n",
      "sss = StratifiedShuffleSplit(Y, n_iter=4, test_size=4, random_state=0)\n",
      "\n",
      "for train, test in sss:\n",
      "    \n",
      "    print '%s %s' % (train, test)\n",
      "    print 'treino %s >>>>> %s' % (X[train].T, Y[train])\n",
      "    print 'teste %s >>>>> %s' % (X[test].T, Y[test])\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1 9 3 8 2 6 5] [ 0 10  7  4]\n",
        "treino [1 9 3 8 2 6 5] >>>>> [0 3 1 2 0 2 1]\n",
        "teste [ 0 10  7  4] >>>>> [0 3 2 1]\n",
        "\n",
        "\n",
        "[ 3  8 10  1  5  6  0] [4 7 2 9]\n",
        "treino [ 3  8 10  1  5  6  0] >>>>> [1 2 3 0 1 2 0]\n",
        "teste [4 7 2 9] >>>>> [1 2 0 3]\n",
        "\n",
        "\n",
        "[ 3  6  2  5  7 10  1] [9 4 0 8]\n",
        "treino [ 3  6  2  5  7 10  1] >>>>> [1 2 0 1 2 3 0]\n",
        "teste [9 4 0 8] >>>>> [3 1 0 2]\n",
        "\n",
        "\n",
        "[ 4  3  1  8 10  7  0] [6 9 5 2]\n",
        "treino [ 4  3  1  8 10  7  0] >>>>> [1 1 0 2 3 2 0]\n",
        "teste [6 9 5 2] >>>>> [2 3 1 0]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}